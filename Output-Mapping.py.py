# -*- coding: utf-8 -*-
"""Madhuri.Gopal (Nov 4, 2025, 10:28:25â€¯PM)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/cog01jzb08er0kazy1kffsehytkne/locations/us-east1/repositories/3c8cf7c6-f4f0-457a-ae46-fd71462a8085
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Dummy embedding function for demonstration
def get_embedding(text):
    # Convert text to a simple vector based on character codes (not meaningful, just placeholder)
    return np.array([ord(c) for c in text if c.isalnum()][:100] + [0]*100)[:100]

# Dummy PDF sections for demonstration
pdf_sections = [
    {"text": "This section discusses the data privacy policy in detail.", "page": 1},
    {"text": "This section outlines the cybersecurity measures.", "page": 2},
    {"text": "This section explains the employee conduct policy.", "page": 3}
]

# Simulated CSV data
csv_df = pd.DataFrame({
    "Policy Name": ["Data Privacy", "Cybersecurity", "Employee Conduct"],
    "Description": ["Details about data privacy.", "Measures for cybersecurity.", "Rules for employee behavior."]
})

# Simulated second CSV for comparison
csv_df_2 = pd.DataFrame({
    "Policy Name": ["Data Privacy", "Cybersecurity"],
    "Details": ["This section discusses the data privacy policy in detail.", "This section outlines the cybersecurity measures."]
})

# Function to find the best match for a given text in PDF sections
def find_best_pdf_match(text, pdf_sections, get_embedding_func, confidence_threshold=0.5):
    text_emb = get_embedding_func(text).reshape(1, -1)
    section_scores = []
    for section in pdf_sections:
        section_emb = get_embedding_func(section["text"]).reshape(1, -1)
        score = cosine_similarity(text_emb, section_emb)[0][0]
        if score > confidence_threshold:
            section_scores.append({
                "section_preview": section["text"][:100],
                "confidence": round(score, 2),
                "page": section["page"]
            })
    section_scores.sort(key=lambda x: x["confidence"], reverse=True)
    return section_scores[0] if section_scores else None

# Prepare output
output_data = []

for index, row in csv_df.iterrows():
    policy_name = row['Policy Name']
    mapped_policy_row = csv_df_2[csv_df_2['Policy Name'] == policy_name]

    if not mapped_policy_row.empty:
        content_to_map = " ".join(mapped_policy_row.iloc[0].dropna().astype(str).tolist())
        best_match = find_best_pdf_match(content_to_map, pdf_sections, get_embedding)

        if best_match:
            output_data.append({
                "Policy Name": policy_name,
                "Mapped Section": f"Page {best_match['page']}",
                "Confidence": best_match['confidence'],
                "Accuracy": "High" if best_match['confidence'] > 0.7 else "Medium",
                "AI Rationale": f"Content mapped to PDF section on page {best_match['page']} with confidence {best_match['confidence']}."
            })
        else:
            output_data.append({
                "Policy Name": policy_name,
                "Mapped Section": "N/A",
                "Confidence": 0.0,
                "Accuracy": "Low",
                "AI Rationale": "No relevant section found in PDF for the mapped policy."
            })
    else:
        best_match = find_best_pdf_match(row.to_string(), pdf_sections, get_embedding)
        if best_match:
            output_data.append({
                "Policy Name": policy_name,
                "Mapped Section": f"Page {best_match['page']}",
                "Confidence": best_match['confidence'],
                "Accuracy": "High" if best_match['confidence'] > 0.7 else "Medium",
                "AI Rationale": f"Content mapped to PDF section on page {best_match['page']} with confidence {best_match['confidence']}."
            })
        else:
            output_data.append({
                "Policy Name": policy_name,
                "Mapped Section": "N/A",
                "Confidence": 0.0,
                "Accuracy": "Low",
                "AI Rationale": "No relevant section found in PDF."
            })

# Output DataFrame
output_df = pd.DataFrame(output_data)
print(output_df)

# prompt: Extend the above example to include 2 CSV files ?


import pandas as pd
import numpy as np
#import pandas as pd
#import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from google.colab import files

# Ensure the embedding and matching functions are defined (they are from your
from sklearn.metrics.pairwise import cosine_similarity

# Dummy embedding function for demonstration
def get_embedding(text):
    # Convert text to a simple vector based on character codes (not meaningful, just placeholder)
    return np.array([ord(c) for c in text if c.isalnum()][:100] + [0]*100)[:100]

# Dummy PDF sections for demonstration
pdf_sections = [
    {"text": "This section discusses the data privacy policy in detail.", "page": 1},
    {"text": "This section outlines the cybersecurity measures.", "page": 2},
    {"text": "This section explains the employee conduct policy.", "page": 3},
    {"text": "This section covers the company's financial reporting standards.", "page": 4},
    {"text": "This section details the intellectual property guidelines.", "page": 5}
]

# Simulated CSV data
csv_df_1 = pd.DataFrame({
    "Policy Name": ["Data Privacy", "Cybersecurity", "Employee Conduct"],
    "Description": ["Details about data privacy.", "Measures for cybersecurity.", "Rules for employee behavior."]
})

# Simulated second CSV for comparison
csv_df_2 = pd.DataFrame({
    "Policy Name": ["Data Privacy", "Cybersecurity", "Financial Reporting"],
    "Details": ["This section discusses the data privacy policy in detail.", "This section outlines the cybersecurity measures.", "This section covers the company's financial reporting standards."]
})

# Function to find the best match for a given text in PDF sections
def find_best_pdf_match(text, pdf_sections, get_embedding_func, confidence_threshold=0.5):
    text_emb = get_embedding_func(text).reshape(1, -1)
    section_scores = []
    for section in pdf_sections:
        section_emb = get_embedding_func(section["text"]).reshape(1, -1)
        score = cosine_similarity(text_emb, section_emb)[0][0]
        if score > confidence_threshold:
            section_scores.append({
                "section_preview": section["text"][:100],
                "confidence": round(score, 2),
                "page": section["page"]
            })
    section_scores.sort(key=lambda x: x["confidence"], reverse=True)
    return section_scores[0] if section_scores else None

# Prepare output
output_data = []

# Process CSV 1
for index, row in csv_df_1.iterrows():
    policy_name = row['Policy Name']
    mapped_policy_row = csv_df_2[csv_df_2['Policy Name'] == policy_name]

    if not mapped_policy_row.empty:
        content_to_map = " ".join(mapped_policy_row.iloc[0].dropna().astype(str).tolist())
        best_match = find_best_pdf_match(content_to_map, pdf_sections, get_embedding)

        if best_match:
            output_data.append({
                "CSV Source": "CSV 1",
                "Policy Name": policy_name,
                "Mapped Section": f"Page {best_match['page']}",
                "Confidence": best_match['confidence'],
                "Accuracy": "High" if best_match['confidence'] > 0.7 else "Medium",
                "AI Rationale": f"Content mapped to PDF section on page {best_match['page']} with confidence {best_match['confidence']}."
            })
        else:
            output_data.append({
                "CSV Source": "CSV 1",
                "Policy Name": policy_name,
                "Mapped Section": "N/A",
                "Confidence": 0.0,
                "Accuracy": "Low",
                "AI Rationale": "No relevant section found in PDF for the mapped policy."
            })
    else:
        best_match = find_best_pdf_match(row.to_string(), pdf_sections, get_embedding)
        if best_match:
            output_data.append({
                "CSV Source": "CSV 1",
                "Policy Name": policy_name,
                "Mapped Section": f"Page {best_match['page']}",
                "Confidence": best_match['confidence'],
                "Accuracy": "High" })

    print(output_data)

# prompt: Generate the same output from the files provided in the prompt in the code ?


import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Dummy embedding function for demonstration
def get_embedding(text):
    # Convert text to a simple vector based on character codes (not meaningful, just placeholder)
    return np.array([ord(c) for c in text if c.isalnum()][:100] + [0]*100)[:100]

# Dummy PDF sections for demonstration
pdf_sections = [
    {"text": "This section discusses the data privacy policy in detail.", "page": 1},
    {"text": "This section outlines the cybersecurity measures.", "page": 2},
    {"text": "This section explains the employee conduct policy.", "page": 3},
    {"text": "This section covers the company's financial reporting standards.", "page": 4},
    {"text": "This section details the intellectual property guidelines.", "page": 5}
]

# Simulated CSV data
csv_df_1 = pd.DataFrame({
    "Policy Name": ["Data Privacy", "Cybersecurity", "Employee Conduct"],
    "Description": ["Details about data privacy.", "Measures for cybersecurity.", "Rules for employee behavior."]
})

# Simulated second CSV for comparison
csv_df_2 = pd.DataFrame({
    "Policy Name": ["Data Privacy", "Cybersecurity", "Financial Reporting"],
    "Details": ["This section discusses the data privacy policy in detail.", "This section outlines the cybersecurity measures.", "This section covers the company's financial reporting standards."]
})

# Function to find the best match for a given text in PDF sections
def find_best_pdf_match(text, pdf_sections, get_embedding_func, confidence_threshold=0.5):
    text_emb = get_embedding_func(text).reshape(1, -1)
    section_scores = []
    for section in pdf_sections:
        section_emb = get_embedding_func(section["text"]).reshape(1, -1)
        score = cosine_similarity(text_emb, section_emb)[0][0]
        if score > confidence_threshold:
            section_scores.append({
                "section_preview": section["text"][:100],
                "confidence": round(score, 2),
                "page": section["page"]
            })
    section_scores.sort(key=lambda x: x["confidence"], reverse=True)
    return section_scores[0] if section_scores else None

# Prepare output
output_data = []

# Process CSV 1
for index, row in csv_df_1.iterrows():
    policy_name = row['Policy Name']
    mapped_policy_row = csv_df_2[csv_df_2['Policy Name'] == policy_name]

    if not mapped_policy_row.empty:
        content_to_map = " ".join(mapped_policy_row.iloc[0].dropna().astype(str).tolist())
        best_match = find_best_pdf_match(content_to_map, pdf_sections, get_embedding)

        if best_match:
            output_data.append({
                "CSV Source": "CSV 1",
                "Policy Name": policy_name,
                "Mapped Section": f"Page {best_match['page']}",
                "Confidence": best_match['confidence'],
                "Accuracy": "High" if best_match['confidence'] > 0.7 else "Medium",
                "AI Rationale": f"Content mapped to PDF section on page {best_match['page']} with confidence {best_match['confidence']}."
            })
        else:
            output_data.append({
                "CSV Source": "CSV 1",
                "Policy Name": policy_name,
                "Mapped Section": "N/A",
                "Confidence": 0.0,
                "Accuracy": "Low",
                "AI Rationale": "No relevant section found in PDF for the mapped policy."
            })
    else:
        best_match = find_best_pdf_match(row.to_string(), pdf_sections, get_embedding)
        if best_match:
            output_data.append({
                "CSV Source": "CSV 1",
                "Policy Name": policy_name,
                "Mapped Section": f"Page {best_match['page']}",
                "Confidence": best_match['confidence'],
                "Accuracy": "High"  })

print(output_data)

# prompt: Generate a code to compare 2 CSV with policy and create an output with the following format - Policy Name , Mapped Section, Confidence , Accuracy, AI Rationale. Consider the files in the folder ?


import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os

# Dummy embedding function for demonstration
def get_embedding(text):
    # Convert text to a simple vector based on character codes (not meaningful, just placeholder)
    return np.array([ord(c) for c in text if c.isalnum()][:100] + [0]*100)[:100]

# Dummy PDF sections for demonstration
pdf_sections = [
    {"text": "This section discusses the data privacy policy in detail.", "page": 1},
    {"text": "This section outlines the cybersecurity measures.", "page": 2},
    {"text": "This section explains the employee conduct policy.", "page": 3},
    {"text": "This section covers the company's financial reporting standards.", "page": 4},
    {"text": "This section details the intellectual property guidelines.", "page": 5}
]

# Function to find the best match for a given text in PDF sections
def find_best_pdf_match(text, pdf_sections, get_embedding_func, confidence_threshold=0.5):
    text_emb = get_embedding_func(text).reshape(1, -1)
    section_scores = []
    for section in pdf_sections:
        section_emb = get_embedding_func(section["text"]).reshape(1, -1)
        score = cosine_similarity(text_emb, section_emb)[0][0]
        if score > confidence_threshold:
            section_scores.append({
                "section_preview": section["text"][:100],
                "confidence": round(score, 2),
                "page": section["page"]
            })
    section_scores.sort(key=lambda x: x["confidence"], reverse=True)
    return section_scores[0] if section_scores else None

# Get a list of all CSV files in the current directory
csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]

if len(csv_files) < 2:
    print("Please ensure there are at least two CSV files in the directory to compare.")
else:
    # Load the first two CSV files
    csv_df_1 = pd.read_csv(csv_files[0])
    csv_df_2 = pd.read_csv(csv_files[1])

    output_data = []

    # Process CSV 1
    for index, row in csv_df_1.iterrows():
        policy_name = row['Policy Name']
        mapped_policy_row = csv_df_2[csv_df_2['Policy Name'] == policy_name]

        if not mapped_policy_row.empty:
            content_to_map = " ".join(mapped_policy_row.iloc[0].dropna().astype(str).tolist())
            best_match = find_best_pdf_match(content_to_map, pdf_sections, get_embedding)

            if best_match:
                output_data.append({
                    "CSV Source": csv_files[0],
                    "Policy Name": policy_name,
                    "Mapped Section": f"Page {best_match['page']}",
                    "Confidence": best_match['confidence'],
                    "Accuracy": "High" if best_match['confidence'] > 0.7 else "Medium",
                    "AI Rationale": f"Content mapped to PDF section on page {best_match['page']} with confidence {best_match['confidence']}."
                })
            else:
                output_data.append({
                    "CSV Source": csv_files[0],
                    "Policy Name": policy_name,
                    "Mapped Section": "N/A",
                    "Confidence": 0.0,
                    "Accuracy": "Low",
                    "AI Rationale": "No relevant section found in PDF for the mapped policy."
                })
        else:
            best_match = find_best_pdf_match(row.to_string(), pdf_sections, get_embedding)
            if best_match:
                output_data.append({
                    "CSV Source": csv_files[0],
                    "Policy Name": policy_name,
                    "Mapped Section": f"Page {best_match['page']}",
                    "Confidence": best_match['confidence'],
                    "Accuracy": "High" if best_match['confidence'] > 0.7 else "Medium"
                })
print(output_data)
output_df = pd.DataFrame(output_data)
output_df.to_csv('output.csv', index=False)

# prompt: Print the output to a CSV file ?

output_df = pd.DataFrame(output_data)
output_df.to_csv('output.csv', index=False)